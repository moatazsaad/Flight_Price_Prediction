{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c33f57",
   "metadata": {},
   "source": [
    "# <center><b>Flight Price Predictor ML</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc31088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder , RobustScaler\n",
    "from category_encoders import BinaryEncoder , OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4af7d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10281 entries, 0 to 10280\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Airline               10281 non-null  object        \n",
      " 1   Date_of_Journey       10281 non-null  datetime64[ns]\n",
      " 2   Source                10281 non-null  object        \n",
      " 3   Destination           10281 non-null  object        \n",
      " 4   Route                 10281 non-null  object        \n",
      " 5   Dep_Time              10281 non-null  object        \n",
      " 6   Arrival_Time          10281 non-null  object        \n",
      " 7   Duration              10281 non-null  int64         \n",
      " 8   Additional_Info       10281 non-null  object        \n",
      " 9   Price                 10281 non-null  int64         \n",
      " 10  Month_of_Journey_Num  10281 non-null  int64         \n",
      " 11  Month_of_Journey      10281 non-null  object        \n",
      " 12  Day_of_Journey_Num    10281 non-null  int64         \n",
      " 13  Day_of_Journey        10281 non-null  object        \n",
      " 14  Distance              10281 non-null  object        \n",
      " 15  Stops_Counts          10281 non-null  int64         \n",
      " 16  Dep_Hour              10281 non-null  int32         \n",
      " 17  Arrival_Month         10281 non-null  object        \n",
      " 18  Arrival_Day           10281 non-null  object        \n",
      " 19  Day_Difference        10281 non-null  bool          \n",
      " 20  Categorized_Duration  10281 non-null  object        \n",
      " 21  Meal                  10281 non-null  int64         \n",
      " 22  Arrival_Hour          10281 non-null  int32         \n",
      " 23  Arrival_Day_Period    10281 non-null  object        \n",
      " 24  Dep_Day_Period        10281 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), int32(2), int64(6), object(15)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_pickle(\"Flight_Price_Detection_After_EDA.pkl\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b298c6",
   "metadata": {},
   "source": [
    "### Data Preparation for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defb23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df.drop(['Date_of_Journey' , 'Day_of_Journey' , 'Route' , 'Duration' , 'Additional_Info' , 'Arrival_Day' , 'Arrival_Month' , 'Month_of_Journey' , 'Dep_Time' , 'Arrival_Time' , 'Day_Difference'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2330e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6b38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6c1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54d4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical features using column transformer\n",
    "# order_encoder = OrdinalEncoder(cols = [\"Distance\" , \"Categorized_Duration\"] , mapping = [{'col' : 'Distance' , 'mapping': {'short_dist':1 , 'medium_dist':2 , 'long_dist':3}} , {'col' : \"Categorized_Duration\" , 'mapping' : {'Short_duration':1 , 'Medium_duration':2 , 'Long_duration':3} }])\n",
    "Encoder = ColumnTransformer(transformers = [(\"OrE\" , OrdinalEncoder(cols = [\"Distance\" , \"Categorized_Duration\"] , mapping = [{'col' : 'Distance' , 'mapping': {'short_dist':1 ,'medium_dist':2 ,'long_dist':3}} , {'col' : \"Categorized_Duration\" , 'mapping' : {'Short_duration':1 , 'Medium_duration':2 , 'Long_duration':3} }]) , [\"Distance\" , \"Categorized_Duration\"]) , (\"BE\" , BinaryEncoder() , ['Airline' , 'Source' , 'Destination' , 'Dep_Day_Period' , 'Arrival_Day_Period' , 'Day_of_Journey_Num'] )] , remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7f8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataframe into feature and target variables\n",
    "x = df.drop(\"Price\" , axis = 1 )\n",
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c4fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of classification models\n",
    "models = list()\n",
    "models.append((\"LR\" , LinearRegression()))\n",
    "models.append((\"KNN\" , KNeighborsRegressor()))\n",
    "models.append((\"CART\" , DecisionTreeRegressor()))\n",
    "models.append((\"RF\" , RandomForestRegressor()))\n",
    "# models.append((\"SVM\" , SVR()))\n",
    "models.append((\"XG\" , XGBRegressor()))\n",
    "# models.append((\"MLP\", MLPRegressor(hidden_layer_sizes=(512,256,128,64,32, ) , max_iter = 1000 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb7cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Train_r2 0.5857265518218668\n",
      "----------\n",
      "Test_r2 0.579932579241627\n",
      "--------------------\n",
      "\n",
      "\n",
      "KNN\n",
      "Train_r2 0.8847433314302924\n",
      "----------\n",
      "Test_r2 0.8174544135273083\n",
      "--------------------\n",
      "\n",
      "\n",
      "CART\n",
      "Train_r2 0.9794544202049309\n",
      "----------\n",
      "Test_r2 0.8359738784410988\n",
      "--------------------\n",
      "\n",
      "\n",
      "RF\n",
      "Train_r2 0.9704168982814668\n",
      "----------\n",
      "Test_r2 0.8906571745039298\n",
      "--------------------\n",
      "\n",
      "\n",
      "XG\n",
      "Train_r2 0.9507210322689076\n",
      "----------\n",
      "Test_r2 0.9048158974141783\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing the performance of different machine learning models using cross-validation and pipeline\n",
    "for model in models:\n",
    "    steps = list()\n",
    "    steps.append((\"Encoder\" , Encoder))\n",
    "    steps.append((\"Scaler\" , RobustScaler()))\n",
    "    steps.append(model)\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "    scores = cross_validate(pipeline , x , y , scoring = \"r2\"  , cv = 5 , return_train_score = True)\n",
    "    print(model[0])\n",
    "    print(\"Train_r2\" , scores[\"train_score\"].mean() )\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Test_r2\" , scores[\"test_score\"].mean())\n",
    "    print(\"-\" * 20)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9871b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBregressor has the best performance\n",
    "steps = list()\n",
    "steps.append((\"Encoder\" , Encoder))\n",
    "steps.append((\"Scaler\" , RobustScaler()))\n",
    "steps.append((\"XG\" , XGBRegressor()))\n",
    "pipeline = Pipeline(steps = steps)\n",
    "scores = cross_validate(pipeline , x , y , scoring = \"r2\"  ,cv = 5 , return_train_score = True , return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1dfc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9507210322689076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['train_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bb1f46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9048158974141783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5547c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['estimator'][0]['XG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc6d396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning hyperparameters of XGBoost model using grid search cross-validation\n",
    "param =  {\n",
    "    \"XG__learning_rate\": [ 0.15, 0.2, 0.25],\n",
    "    \"XG__max_depth\": [4, 6, 8],\n",
    "    \"XG__n_estimators\": [250, 300, 350],\n",
    "    \"XG__reg_lambda\": [2, 2.5, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37987e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('Encoder',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('OrE',\n",
       "                                                                         OrdinalEncoder(cols=['Distance',\n",
       "                                                                                              'Categorized_Duration'],\n",
       "                                                                                        mapping=[{'col': 'Distance',\n",
       "                                                                                                  'data_type': dtype('O'),\n",
       "                                                                                                  'mapping': short_dist     1\n",
       "medium_dist    2\n",
       "long_dist      3\n",
       "dtype: int64},\n",
       "                                                                                                 {'col': 'Categorized_Duration',\n",
       "                                                                                                  'data_type': dtype('O'),\n",
       "                                                                                                  'mapping': Short_d...\n",
       "                                                     max_depth=None,\n",
       "                                                     max_leaves=None,\n",
       "                                                     min_child_weight=None,\n",
       "                                                     missing=nan,\n",
       "                                                     monotone_constraints=None,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     num_parallel_tree=None,\n",
       "                                                     predictor=None,\n",
       "                                                     random_state=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'XG__learning_rate': [0.15, 0.2, 0.25],\n",
       "                         'XG__max_depth': [4, 6, 8],\n",
       "                         'XG__n_estimators': [250, 300, 350],\n",
       "                         'XG__reg_lambda': [2, 2.5, 3]},\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = []\n",
    "steps.append((\"Encoder\" , Encoder))\n",
    "steps.append((\"Scaler\" , RobustScaler()))\n",
    "steps.append((\"XG\" , XGBRegressor()))\n",
    "pipeline_ = Pipeline(steps = steps)\n",
    "grid_search = GridSearchCV(estimator = pipeline_ , param_grid = param , cv = 5 , scoring = \"r2\" , return_train_score = True , n_jobs = -1)\n",
    "grid_search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4faa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'XG__learning_rate': 0.15, 'XG__max_depth': 6, 'XG__n_estimators': 350, 'XG__reg_lambda': 3}\n",
      "Mean train score:  0.9514719506445093\n",
      "Mean test score:  0.8988497811183154\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Mean train score: \", grid_search.cv_results_[\"mean_train_score\"].mean())\n",
    "print(\"Mean test score: \", grid_search.cv_results_[\"mean_test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "steps.append((\"Encoder\" , Encoder))\n",
    "steps.append((\"Scaler\" , RobustScaler()))\n",
    "steps.append((\"XG\" , XGBRegressor()))\n",
    "pipeline = Pipeline(steps = steps)\n",
    "pipeline.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model , \"Model.pkl\")\n",
    "joblib.dump(x.columns , \"Inputs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(x[\"Meal\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa41d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd \n",
    "import joblib\n",
    "import sklearn\n",
    "import xgboost\n",
    "import category_encoders\n",
    "\n",
    "# Load the trained model and input variables\n",
    "Model = joblib.load(\"Model.pkl\")\n",
    "Inputs = joblib.load(\"Inputs.pkl\")\n",
    "\n",
    "# Function for making flight price predictions\n",
    "def prediction(Airline , Source , Destination ,\n",
    "               Month_of_Journey_Num , Day_of_Journey_Num ,\n",
    "               Distance , Stops_Counts , Dep_Hour , Categorized_Duration,\n",
    "               Meal, Arrival_Hour, Arrival_Day_Period,\n",
    "       Dep_Day_Period):\n",
    "    # Create a test DataFrame with the input variables\n",
    "    test_df = pd.DataFrame(columns = Inputs)\n",
    "    test_df.at[0,\"Airline\"] = Airline\n",
    "    test_df.at[0,\"Source\"] = Source\n",
    "    test_df.at[0,\"Destination\"] = Destination\n",
    "    test_df.at[0,\"Month_of_Journey\"] = Month_of_Journey_Num\n",
    "    test_df.at[0,\"Day_of_Journey_Num\"] = Day_of_Journey_Num\n",
    "    test_df.at[0,\"Distance\"] = Distance\n",
    "    test_df.at[0,\"Stops_Counts\"] = Stops_Counts\n",
    "    test_df.at[0,\"Dep_Hour\"] = Dep_Hour\n",
    "    test_df.at[0,\"Categorized_Duration\"] = Categorized_Duration\n",
    "    test_df.at[0,\"Meal\"] = Meal\n",
    "    test_df.at[0,\"Arrival_Hour\"] = Arrival_Hour\n",
    "    test_df.at[0,\"Arrival_Day_Period\"] = Arrival_Day_Period\n",
    "    test_df.at[0,\"Dep_Day_Period\"] = Dep_Day_Period\n",
    "    # Make predictions using the loaded model\n",
    "    result = Model.predict(test_df)\n",
    "    return result[0]\n",
    "def main():\n",
    "    # Set up the Streamlit app title and input widgets\n",
    "    st.title(\"Flight Price Predictor\")\n",
    "    Airline = st.selectbox(\"Airline name\" ,['Air India', 'Jet Airways', 'IndiGo', 'SpiceJet',\n",
    "       'Multiple carriers', 'GoAir', 'Vistara', 'Air Asia'] )\n",
    "    Source  = st.selectbox(\"Departure city\" , ['Kolkata', 'Delhi', 'Banglore', 'Chennai', 'Mumbai'])\n",
    "    Destination = st.selectbox(\"Arrival city\" ,['Banglore', 'Cochin', 'New Delhi', 'Kolkata', 'Delhi', 'Hyderabad'] )\n",
    "    Month_of_Journey_Num = st.selectbox(\"Departure month\" ,[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] )\n",
    "    Stops_Counts = st.selectbox(\"Number of Stops\" , [2, 1, 0, 3, 4])\n",
    "    Day_of_Journey_Num = st.selectbox(\"Day of travel\" , [ 1,  9, 12, 24, 27, 18,  3, 15,  6, 21])\n",
    "    Categorized_Duration = st.selectbox(\"Flight duration\" , ['Short duration', 'Medium duration', 'Long duration'])\n",
    "    Distance = st.selectbox(\"Flight distance\" , ['medium distance', 'long distance', 'short distance'])\n",
    "    Dep_Day_Period = st.selectbox(\"Departure period\" , ['Early Morning', 'Afternoon', 'Evening', 'Night'])\n",
    "    Arrival_Day_Period = st.selectbox(\"Arrival period\" ,['Afternoon', 'Night', 'Evening', 'Early Morning'] )\n",
    "    Dep_Hour = st.selectbox(\"Departure time\",[0 , 1, 2 , 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])\n",
    "    Arrival_Hour = st.selectbox(\"Arrival time\",[0 , 1, 2 , 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])\n",
    "    Meal = st.selectbox(\"Meal\" , [0, 1])\n",
    "    # Perform prediction when the \"predict\" button is clicked\n",
    "    if st.button(\"predict\"):\n",
    "        results = prediction(Airline , Source , Destination , Month_of_Journey_Num , Day_of_Journey_Num , Distance , Stops_Counts , Dep_Hour , Categorized_Duration ,\n",
    "               Meal , Arrival_Hour , Arrival_Day_Period , Dep_Day_Period)\n",
    "        st.text(f\"The flight cost will be {round(results)} Indian Rupee.\")\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687eab19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
